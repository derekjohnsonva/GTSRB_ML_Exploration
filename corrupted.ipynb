{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Camera Attacks\n",
    "\n",
    "In this notebook we will test the efficacy of several attacks. We will begin with the line drawing attack and move on to the blurring attack. We expect to see a significant decrease in classification accuracy after using these attacks.\n",
    "\n",
    "After this, we will attempt to boost the classification accuracy.\n",
    "\n",
    "The classification accuracy of our initial model on the un-altered tests data was over $97\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDLIB\n",
    "import os\n",
    "import typing\n",
    "import csv\n",
    "import random\n",
    "# Packages\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"GTSRB\"\n",
    "TRAINING_DATA_PATH = os.path.join(DATA_DIR, \"Final_Training/Images\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Drawing\n",
    "\n",
    "This first attack is meant to simulate a crack in the camera lense of the device taking pictures of the traffic signs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance(p1, p2):\n",
    "\n",
    "    i1, i2 = int(p1[0]), int(p2[0])\n",
    "\n",
    "    # if both x-coordinates are floats and they have the same integer part\n",
    "    if i1 != p1[0] and i2 != p2[0] and i1 == i2:\n",
    "\n",
    "        # find the decimal parts\n",
    "        d1, d2 = p1[0] - i1, p2[0] - i2\n",
    "\n",
    "        # find the smaller \"C\"\n",
    "        x = min(d1 + d2, (1-d1) + (1-d2))\n",
    "\n",
    "        # add the y distance to the \"C\" distance\n",
    "        return abs(p1[1] - p2[1]) + x\n",
    "\n",
    "    # repeat with the \"y-coordinates are floats\" case\n",
    "    i1, i2 = int(p1[1]), int(p2[1])\n",
    "    if i1 != p1[1] and i2 != p2[1] and i1 == i2:\n",
    "        d1, d2 = p1[1] - i1, p2[1] - i2\n",
    "        y = min(d1 + d2, (1-d1) + (1-d2))\n",
    "        return abs(p1[0] - p2[0]) + y\n",
    "\n",
    "    # simple case, return the Manhattan distance\n",
    "    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n",
    "\n",
    "def insert_lines(image) :\n",
    "    image_data = image\n",
    "    unmodified_input_image = image_data\n",
    "    \n",
    "    #understand the image dimensions\n",
    "    image_height = image_data.shape[0]\n",
    "    image_width = image_data.shape[1]\n",
    "    \n",
    "    #define the min legth of the line to be drawn on the image\n",
    "    min_length = round(0.25 * image_height)\n",
    "\n",
    "    line_length = 0\n",
    "    iter = 0 \n",
    "    while (line_length < min_length) and (iter < 10) :\n",
    "        x = [random.randint(0, image_height), random.randint(0, image_width)]\n",
    "        y = [random.randint(0, image_height), random.randint(0, image_width)]\n",
    "        line_length = minimum_distance(x, y)\n",
    "        iter = iter + 1\n",
    "\n",
    "    random_col = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "    cv.line(image_data, x, y, random_col, 1)\n",
    "\n",
    "    output_image = cv.addWeighted(image_data, 0.15, unmodified_input_image, 0.85, 0)\n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrafficSignsTest(rootpath: str) -> typing.Tuple[list[cv.Mat], list[str]]:\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    with open(os.path.join(rootpath, 'GT-final_test.csv')) as gtFile:\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            file_link = os.path.join(rootpath, row[0])\n",
    "            image = cv.imread(file_link) # read image, the 1th column is the filename\n",
    "            images.append(image)\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "    return images, labels\n",
    "\n",
    "def run_model_on_data(model: keras.Model, images: list[cv.Mat], labels: list[str]) -> dict[str, float]:\n",
    "    \"\"\"_summary_: Runs the model on the given images and labels.\n",
    "\n",
    "    Args:\n",
    "        model (keras.Model): The model to run on the images.\n",
    "        images (list[cv.Mat]): The images to run on. These should already be processed.\n",
    "        labels (list[str]): The labels to run on.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with two keys: 'accuracy' and 'loss'.\n",
    "    \"\"\"\n",
    "    test_images = np.array(images).astype(np.float32) # this allows us to convert it to a tensor\n",
    "    test_images = test_images/255 # Everyone seems to do this so we will too!!!\n",
    "    test_labels = np.array(labels).astype(np.float32)\n",
    "\n",
    "    assert len(test_images) == len(test_labels)\n",
    "\n",
    "    result = model.evaluate(test_images, test_labels)\n",
    "    return dict(zip(model.metrics_names, result))\n",
    "\n",
    "def process_images(images: list[cv.Mat]):\n",
    "    output = []\n",
    "    for image in images:\n",
    "        image_with_line = insert_lines(image)\n",
    "        resized_image = cv.resize(image_with_line, (32,32)) # resize to 32x32\n",
    "        output.append(resized_image) # resize to 32x32\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model. If you want to retrain, delete the file: cnn_v3.h5\n",
      " 25/395 [>.............................] - ETA: 1s - loss: 0.3329 - accuracy: 0.9475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dej3tc/Documents/ML/GTSRB_ML_Exploration/env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 2s 5ms/step - loss: 0.3638 - accuracy: 0.9459\n",
      "{'loss': 0.36384642124176025, 'accuracy': 0.9459224343299866}\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_PATH = os.path.join(DATA_DIR, \"Final_Test/Images\")\n",
    "MODEL_NAME = \"cnn_v3.h5\"\n",
    "\n",
    "# Load the Model\n",
    "model = None\n",
    "if os.path.exists(MODEL_NAME):\n",
    "    print(\"Loading existing model. If you want to retrain, delete the file: \" + MODEL_NAME)\n",
    "    model = keras.models.load_model(MODEL_NAME)\n",
    "else:\n",
    "    print(\"No existing model found.\")\n",
    "    exit(1)\n",
    "\n",
    "real_test_images, real_test_labels = readTrafficSignsTest(TEST_DATA_PATH)\n",
    "processed_test_images = process_images(real_test_images)\n",
    "\n",
    "result_dict = run_model_on_data(model, processed_test_images, real_test_labels)\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Adding lines to the images after standardizing their size to 32x32 resulted in drop in accuracy to $93.87\\%$\n",
    "\n",
    "Adding lines to the images before standardizing their size to 32x32 resulted in drop in accuracy to $94.6\\%$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0748de0ab3ca80ffb25b4ddd2318bb4a5ef5fca12a43a3e8d1e1d6738f8e7819"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
