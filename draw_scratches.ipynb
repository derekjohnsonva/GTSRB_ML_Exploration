{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Scratch Test\n",
    "This section is to draw random scratches on an image and check how reilient the classifier is to these randomly introduced noises.\n",
    "To introduce the random scratches, we basically plot a straight line and some dots on an image using the matplotlib. \n",
    "The code is inspired from this [page](https://www.geeksforgeeks.org/plot-a-point-or-a-line-on-an-image-with-matplotlib/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDLIB\n",
    "import os\n",
    "import typing\n",
    "import csv\n",
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import image\n",
    "import random\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"GTSRB\"\n",
    "TRAINING_DATA_PATH = os.path.join(DATA_DIR, \"Final_Training/Images\")\n",
    "CORRUPTED_DATA_PATH = os.path.join(DATA_DIR, \"corrupted_Data/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance(p1, p2):\n",
    "\n",
    "    i1, i2 = int(p1[0]), int(p2[0])\n",
    "\n",
    "    # if both x-coordinates are floats and they have the same integer part\n",
    "    if i1 != p1[0] and i2 != p2[0] and i1 == i2:\n",
    "\n",
    "        # find the decimal parts\n",
    "        d1, d2 = p1[0] - i1, p2[0] - i2\n",
    "\n",
    "        # find the smaller \"C\"\n",
    "        x = min(d1 + d2, (1-d1) + (1-d2))\n",
    "\n",
    "        # add the y distance to the \"C\" distance\n",
    "        return abs(p1[1] - p2[1]) + x\n",
    "\n",
    "    # repeat with the \"y-coordinates are floats\" case\n",
    "    i1, i2 = int(p1[1]), int(p2[1])\n",
    "    if i1 != p1[1] and i2 != p2[1] and i1 == i2:\n",
    "        d1, d2 = p1[1] - i1, p2[1] - i2\n",
    "        y = min(d1 + d2, (1-d1) + (1-d2))\n",
    "        return abs(p1[0] - p2[0]) + y\n",
    "\n",
    "    # simple case, return the Manhattan distance\n",
    "    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_height =  59 min_length =  15\n"
     ]
    }
   ],
   "source": [
    "image_data = image.imread('10945.ppm')\n",
    "input_image = image.imread('10945.ppm')\n",
    "\n",
    "image_height = image_data.shape[0]\n",
    "image_width = image_data.shape[1]\n",
    "min_length = round(0.25 * image_height)\n",
    "\n",
    "print(\"Image_height = \", image_height, \"min_length = \", min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_lines(image) :\n",
    "    image_data = image\n",
    "    unmodified_input_image = image_data\n",
    "    \n",
    "    #understand the image dimensions\n",
    "    image_height = image_data.shape[0]\n",
    "    image_width = image_data.shape[1]\n",
    "    \n",
    "    #define the min legth of the line to be drawn on the image\n",
    "    min_length = round(0.25 * image_height)\n",
    "\n",
    "    line_length = 0\n",
    "    iter = 0 \n",
    "    while (line_length < min_length) and (iter < 10) :\n",
    "        x = [random.randint(0, image_height), random.randint(0, image_width)]\n",
    "        y = [random.randint(0, image_height), random.randint(0, image_width)]\n",
    "        line_length = minimum_distance(x, y)\n",
    "        #print(\"The minimum distance is : \", line_length)\n",
    "        iter = iter + 1\n",
    "        #print(\"iter = \", iter)\n",
    "\n",
    "    random_col = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    #plt.plot(x, y, c=random_col, linewidth=2)\n",
    "    #plt.imshow(data)\n",
    "    #plt.show()\n",
    "    #cv.imwrite('output.ppm', plt)\n",
    "    #print(\"hello world\")\n",
    "\n",
    "    cv.line(image_data, x, y, random_col, 1)\n",
    "\n",
    "    output_image = cv.addWeighted(image_data, 0.15, unmodified_input_image, 0.85, 0)\n",
    "\n",
    "    #cv.imshow(\"Image\", input_image)\n",
    "    #cv.imwrite('output.ppm', output_image)\n",
    "\n",
    "    #print(ssim(np.array(image_data), np.array(unmodified_input_image), multichannel=True))\n",
    "    return output_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=29'>30</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(labels)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m images, labels\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=32'>33</a>\u001b[0m images, labels \u001b[39m=\u001b[39m readTrafficSigns(TRAINING_DATA_PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=33'>34</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(images) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(labels)\n",
      "\u001b[1;32m/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb Cell 7'\u001b[0m in \u001b[0;36mreadTrafficSigns\u001b[0;34m(rootpath)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m labels \u001b[39m=\u001b[39m [] \u001b[39m# corresponding labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# loop over all 42 classes\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m43\u001b[39m)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m     prefix \u001b[39m=\u001b[39m rootpath \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mformat\u001b[39m(c, \u001b[39m'\u001b[39m\u001b[39m05d\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# subdirectory for class\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bportal03.cs.virginia.edu/p/qprocessingfulcrum/ml_project/GTSRB_ML_Exploration/draw_scratches.ipynb#ch0000007vscode-remote?line=11'>12</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(prefix \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGT-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m \u001b[39mformat\u001b[39m(c, \u001b[39m'\u001b[39m\u001b[39m05d\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m gtFile:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "def readTrafficSigns(rootpath: str) -> typing.Tuple[np.array, np.array]:\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    processed_images = []   # array to hold the processed images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in tqdm(range(0,43)):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        with open(prefix + 'GT-'+ format(c, '05d') + '.csv') as gtFile:\n",
    "            gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "            next(gtReader) # skip header\n",
    "            # loop over all images in current annotations file\n",
    "            for row in tqdm(gtReader):\n",
    "                #image_filename = row[0]\n",
    "                print(\"File Path = \", (prefix + row[0]))\n",
    "                image = cv.imread(prefix + row[0]) # read image, the 1th column is the filename\n",
    "                image = cv.resize(image, (32,32)) # resize to 32x32\n",
    "                # image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) # convert to grayscale\n",
    "                processed_image = insert_lines(image)\n",
    "                corrupted_output_filename = \"corrupted_\" + row[0]\n",
    "                cv.imwrite(prefix + corrupted_output_filename, processed_image)\n",
    "                images.append(image)\n",
    "                labels.append(row[7]) # the 8th column is the label\n",
    "    # convert the list to numpy arrays\n",
    "    images = np.array(images).astype(np.float32) # this allows us to convert it to a tensor\n",
    "    images = images/255 # Everyone seems to do this so we will too!!!\n",
    "    labels = np.array(labels).astype(np.float32)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = readTrafficSigns(TRAINING_DATA_PATH)\n",
    "assert len(images) == len(labels)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb4bced920e404e701204d172d5ad5d14b88e5d1cbc07f76649fd8d5a38c144f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('myEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
